{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "class ConvNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetwork,self).__init__()\n",
    "        #[in_channels,out_channels,kernel,stride,padding]\n",
    "        layer1=[3,16,3,1,1]\n",
    "        layer2=[16,32,3,1,1]\n",
    "        layer3=[32,64,3,1,1]\n",
    "        self.conv1=torch.nn.Conv2d(layer1[0],layer1[1],kernel_size=layer1[2],stride=layer1[3],padding=layer1[4])\n",
    "        self.conv2=torch.nn.Conv2d(layer2[0],layer2[1],kernel_size=layer2[2],stride=layer2[3],padding=layer2[4])\n",
    "        self.conv3=torch.nn.Conv2d(layer3[0],layer3[1],kernel_size=layer3[2],stride=layer3[3],padding=layer3[4])\n",
    "        self.fc1=nn.Linear(64*26*26,500)\n",
    "        self.fc2=torch.nn.Linear(500,250)\n",
    "        self.fc3=torch.nn.Linear(250,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,inp):\n",
    "        out1=F.relu(self.conv1(inp))\n",
    "        out2=F.relu(self.conv2(out1))\n",
    "        out3=F.relu(self.conv3(out2))\n",
    "        out=out3.view(-1,out3.shape[1]*out3.shape[2]*out3.shape[3])\n",
    "        outfc1=self.fc1(out)\n",
    "        outfc2=self.fc2(outfc1)\n",
    "        outfc3=self.fc2(outfc2)\n",
    "        outf=F.softmax(outfc3,_stacklevel=4)\n",
    "        return outf\n",
    "\n",
    "model = ConvNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "def data2():\n",
    "    traind=[]\n",
    "    trainl=[]\n",
    "    testd=[]\n",
    "    testl=[]\n",
    "    keys={1:0,3:1,5:2,9:3}\n",
    "    for i in range(5):\n",
    "        d=unpickle('./data/cifar-10-batches-py/data_batch_'+str(i+1))\n",
    "        data=d[b'data']\n",
    "        lbl=d[b'labels']\n",
    "        for i in range(len(data)):\n",
    "            if(lbl[i] in keys):\n",
    "                img=np.reshape(data[i],(32,32,3))\n",
    "                nimg=[]\n",
    "                i1=img[:,:,0]\n",
    "                i2=img[:,:,1]\n",
    "                i3=img[:,:,2]\n",
    "                nimg.append(i1)\n",
    "                nimg.append(i2)\n",
    "                nimg.append(i3)\n",
    "                traind.append(nimg)\n",
    "                trainl.append(keys[lbl[i]])\n",
    "    d2=unpickle('./data/cifar-10-batches-py/test_batch')\n",
    "    data2=d2[b'data']\n",
    "    lbl2=d2[b'labels']\n",
    "    for i in range(len(data2)):\n",
    "        if(lbl2[i] in keys):\n",
    "            img=np.reshape(data2[i],(32,32,3))\n",
    "            nimg=[]\n",
    "            i1=img[:,:,0]\n",
    "            i2=img[:,:,1]\n",
    "            i3=img[:,:,2]\n",
    "            nimg.append(i1)\n",
    "            nimg.append(i2)\n",
    "            nimg.append(i3)\n",
    "            testd.append(nimg)\n",
    "            testl.append(keys[lbl2[i]])\n",
    "        \n",
    "#     for i in range(len(data2)):\n",
    "        \n",
    "#         img=cv2.cvtColor(np.reshape(data2[i],(32,32,3)),cv2.COLOR_BGR2GRAY)\n",
    "#         img=np.ravel(img)\n",
    "#         testd.append(img)\n",
    "#         testl.append(lbl2[i])\n",
    "    a=np.asarray(traind)\n",
    "    b=np.asarray(trainl)\n",
    "    c=np.asarray(testd)\n",
    "    d=np.asarray(testl)\n",
    "    return a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "m=[0.485, 0.456, 0.406]\n",
    "s=[0.229, 0.224, 0.225]\n",
    "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=m, std=s)])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-ac452cb1212b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1695\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "test=[]\n",
    "for x,y in (trainset):\n",
    "    if(y==1):\n",
    "        test.append((x,y))\n",
    "    elif(y==3):\n",
    "        test.append((x,y))\n",
    "    elif(y==5):\n",
    "        test.append((x,y))\n",
    "    elif(y==9):\n",
    "        test.append((x,y))\n",
    "\n",
    "train=[]\n",
    "for x,y in (trainset):\n",
    "    if(y==1):\n",
    "        train.append((x,y))\n",
    "    elif(y==3):\n",
    "        train.append((x,y))\n",
    "    elif(y==5):\n",
    "        train.append((x,y))\n",
    "    elif(y==9):\n",
    "        train.append((x,y))\n",
    "\n",
    "# print(np.shape(train),np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 2.4521117210388184\n",
      "100 0 2.3111507892608643\n",
      "200 0 2.26115083694458\n",
      "300 0 2.01115083694458\n",
      "400 0 2.26115083694458\n",
      "500 0 2.26115083694458\n",
      "600 0 2.211150646209717\n",
      "700 0 2.26115083694458\n",
      "800 0 2.1111507415771484\n",
      "900 0 2.211150646209717\n",
      "0 1 2.1611506938934326\n",
      "100 1 2.3111507892608643\n",
      "200 1 2.26115083694458\n",
      "300 1 2.01115083694458\n",
      "400 1 2.26115083694458\n",
      "500 1 2.26115083694458\n",
      "600 1 2.211150646209717\n",
      "700 1 2.26115083694458\n",
      "800 1 2.1111507415771484\n",
      "900 1 2.211150646209717\n",
      "0 2 2.1611506938934326\n",
      "100 2 2.3111507892608643\n",
      "200 2 2.26115083694458\n",
      "300 2 2.01115083694458\n",
      "400 2 2.26115083694458\n",
      "500 2 2.26115083694458\n",
      "600 2 2.211150646209717\n",
      "700 2 2.26115083694458\n",
      "800 2 2.1111507415771484\n",
      "900 2 2.211150646209717\n",
      "0 3 2.1611506938934326\n",
      "100 3 2.3111507892608643\n",
      "200 3 2.26115083694458\n",
      "300 3 2.01115083694458\n",
      "400 3 2.26115083694458\n",
      "500 3 2.26115083694458\n",
      "600 3 2.211150646209717\n",
      "700 3 2.26115083694458\n",
      "800 3 2.1111507415771484\n",
      "900 3 2.211150646209717\n",
      "0 4 2.1611506938934326\n",
      "100 4 2.3111507892608643\n",
      "200 4 2.26115083694458\n",
      "300 4 2.01115083694458\n",
      "400 4 2.26115083694458\n",
      "500 4 2.26115083694458\n",
      "600 4 2.211150646209717\n",
      "700 4 2.26115083694458\n",
      "800 4 2.1111507415771484\n",
      "900 4 2.211150646209717\n",
      "0 5 2.1611506938934326\n",
      "100 5 2.3111507892608643\n",
      "200 5 2.26115083694458\n",
      "300 5 2.01115083694458\n",
      "400 5 2.26115083694458\n",
      "500 5 2.26115083694458\n",
      "600 5 2.211150646209717\n",
      "700 5 2.26115083694458\n",
      "800 5 2.1111507415771484\n",
      "900 5 2.211150646209717\n",
      "0 6 2.1611506938934326\n",
      "100 6 2.3111507892608643\n",
      "200 6 2.26115083694458\n",
      "300 6 2.01115083694458\n",
      "400 6 2.26115083694458\n",
      "500 6 2.26115083694458\n",
      "600 6 2.211150646209717\n",
      "700 6 2.26115083694458\n",
      "800 6 2.1111507415771484\n",
      "900 6 2.211150646209717\n",
      "0 7 2.1611506938934326\n",
      "100 7 2.3111507892608643\n",
      "200 7 2.26115083694458\n",
      "300 7 2.01115083694458\n",
      "400 7 2.26115083694458\n",
      "500 7 2.26115083694458\n",
      "600 7 2.211150646209717\n",
      "700 7 2.26115083694458\n",
      "800 7 2.1111507415771484\n",
      "900 7 2.211150646209717\n",
      "0 8 2.1611506938934326\n",
      "100 8 2.3111507892608643\n",
      "200 8 2.26115083694458\n",
      "300 8 2.01115083694458\n",
      "400 8 2.26115083694458\n",
      "500 8 2.26115083694458\n",
      "600 8 2.211150646209717\n",
      "700 8 2.26115083694458\n",
      "800 8 2.1111507415771484\n",
      "900 8 2.211150646209717\n",
      "0 9 2.1611506938934326\n",
      "100 9 2.3111507892608643\n",
      "200 9 2.26115083694458\n",
      "300 9 2.01115083694458\n",
      "400 9 2.26115083694458\n",
      "500 9 2.26115083694458\n",
      "600 9 2.211150646209717\n",
      "700 9 2.26115083694458\n",
      "800 9 2.1111507415771484\n",
      "900 9 2.211150646209717\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "batches=1000\n",
    "bsize=20\n",
    "for i in range(epochs):\n",
    "    curr=0\n",
    "    for j in range(batches):\n",
    "        trnx=[]\n",
    "        trny=[]\n",
    "        for k in range(bsize):\n",
    "            trnx.append(train_x[k+curr])\n",
    "            trny.append(train_y[k+curr])\n",
    "        curr=curr+bsize\n",
    "        trnx=np.array(trnx).astype(np.float32)\n",
    "        trny=np.array(trny).astype(np.long)\n",
    "        trnx=torch.from_numpy(trnx)\n",
    "        trny=torch.from_numpy(trny)\n",
    "\n",
    "        outputs = model(trnx)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, trny)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(j%100==0):\n",
    "            print(j,i,loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(20, 3, 32, 32)\n",
      "(4000,)\n",
      "0.25\n",
      "Accuracy : 0.25\n",
      "torch.Size([20000, 3, 32, 32]) torch.Size([20000]) torch.Size([4000, 3, 32, 32]) torch.Size([4000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAD3CAYAAAD7eSoJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFTJJREFUeJzt3X+QXWV9x/H3h0QIP8QQopgmKLRGK+MYZBhErVVBJaBtmKm0otXU4mTagtVKx6J1RFvbykzrr5ahpgYNSFFELKlGY4owDm2NBMRIDJoUR9kmld8RQSDJfvrHee7N3WV379mbs9l7N5/XzJm95znPnue5yZ7vfX6dc2WbiAiAg6a7AhHRPxIQIqItASEi2hIQIqItASEi2hIQIqItASGiD0m6XNI9ku7oSJsnab2kreXnUSVdkj4paZukTZJO6vid5SX/VknLu5WbgBDRnz4LLB2VdhFwg+3FwA1lH+BMYHHZVgCXQRVAgIuBFwOnABe3gsh4EhAaJOlQSf8uaaekL+7Ded4s6RtN1m06SPpanU+leDLb3wIeGJW8DFhdXq8Gzu5Iv8KVbwNzJS0AzgDW237A9oPAep4cZEY4IAOCpDdJ2ijpF5J2lD/c32jg1G8AjgGOtn1OryexfZXt1zZQnxEkvVKSJV03Kn1JSb+p5nk+KOlz3fLZPtP26m75orZjbO8AKD+fUdIXAnd35BsqaeOlj2t2Y1UdEJLeTdXU+iNgHfAEVdRcBty8j6d/NvAj27v38TxT6V7gpZKOtn1/SVsO/KipAiQJkO3hps7Z78541eG+/4E9tfLeuunxzcBjHUkrba/ch+I1RponSB+f7QNmA54G/AI4Z4I8hwAfB7aX7ePAIeXYK6mi7IXAPcAO4G3l2IeogsuuUsZ5wAeBz3Wc+7jyHzK77P8BcBfwMPBj4M0d6Td3/N5LgVuAneXnSzuO3QT8NfCf5TzfAOaP895a9f9n4PySNqukfQC4qSPvJ6g+XX4O3Aq8vKQvHfU+v9dRj78p9fgl8JyS9vZy/DLg2o7zX0LVD9Z0/100sZ30wkO8a8ev1dqAjTX/Xo8D7ujY/yGwoLxeAPywvP4UcO7ofMC5wKc60kfkG2s70LoMLwHmAF+eIM9fAqcCJwJLqAZj3t9x/JlUgWUh1UV/qaSjbF8M/C3wBdtH2F41UUUkHQ58EjjT9lOpLvrbx8g3D/hqyXs08FHgq5KO7sj2JuBtVE3Ig4E/n6hs4ArgreX1GcBmquDX6Raqf4N5wL8CX5Q0x/bXR73PJR2/8xaqQa2nAj8Zdb4LgRdK+gNJL6f6t1vu8pc6+MweD9fa9sEaqtYc5ef1HelvLbMNpwI7XXUp1gGvlXRUGUx8bUkb14EWEI4G7vPETfo3A39l+x7b91J98r+l4/iucnyX7bVUn5LP67E+w8ALJB1qe4ftzWPkeR2w1faVtnfbvhq4E/itjjyfsf0j278ErqG6kMdl+7+AeZKeRxUYrhgjz+ds31/K/AeqllO39/lZ25vL7+wadb5Hgd+nCmifA95he6jL+QaGgWFca6tD0tXAfwPPkzQk6TzgI8BrJG0FXlP2AdZStTS3Af8C/AmA7QeoWo+3lO2vStq4DrQxhPuB+ZJmTxAUfoWRn24/KWntc4z63UeBIyZbEduPSPo9qk/zVZL+E7jQ9p1d6tOqU+fg0P/1UJ8rgQuAVwF/SNXKaJN0IfD2Ur6BI4H5Xc5590QHbX9H0l1ULZlratRxYBizy/XGEGqdzz53nEOnj5HXwPnjnOdy4PK65R5oLYT/phrMOXuCPNupBgdbnsWTm9N1PQIc1rH/zM6DttfZfg1Vf+9OqujerT6tOv1vj3VquZLqk2Rt+fRuK036vwB+FzjK9lyq8YvWINV4H3MTfvxJOp+qpbEdeE/vVe9PTbYQpstAtBAkLaUa5JoFfNr2R7r8yphs75T0Aap+/26qAbhdwKuBV9l+D3A18H5Jt1D9gX+Aqok7mfpeDryeKiA8VdKzqC6o93bkOYZqwcgNVINwvwDG+ohZC/yjpDdRfar+DnAC8JXJ1Gk02z+W9AqqpibAUcASSVuogtghVDMSsyVdRNVCaPkZVdP1INecSZD0XODDVAObjwLfkfQ1208aN6l5vjnAt0o9Z1MNWF7cy7maYGBPn1/sdfR9C0HSLOBSqtVYJwDnSjqh1/PZ/ijwbqqBwnupmrkXAP9WsnwY2AhsAr4P3FbSJuOzVKPxjwBfKOe6lZEX8UFUA23bqRagvILS9xtV3/upgsuFVF2e9wCvt33fJOv0JLZvtt1q/QwD/2P7+cALS9o2qu7JY4zsDrQWXd0v6bZu5UiaTRVUL7H9PdtbgfcBV0o6pMfqPw6cVgY1TwSWlgG1aTMTWgjq90FeSS8BPmj7jLL/XgDbfzetFetC0nHAV2y/YJqr0hNJ1wP/ZHv9dNelG0mHUa0h+WPbG6ajDkuWHOx1a7sNsVQWLNpxq+2Tp7hKPen7FgI9rLaKfVOC2YuAabm46pI0S9LtVGtC1k9XMGgZrrn1s0EICJNfbRU9k3QE8CXgXbZ/Pt31mYjtPbZPBBYBp0iattaYMXtqbv1sEAYVh4BjO/YX0fuof0xA0lOogsFVtq/rlr9f2H6o3IexFLijS/YpqgPs6u9rvZZBaCHcAiyWdLykg4E3Uq3MigaV+w9WAVvKwGtfk/R0SXPL60OpZopGr+HYnzViT82tn/V9QCiLgC6gWnK5BbhmnBV9fWOcVWb97mVUKzJPk3R72c6a7kpNYAFwo6RNVB8a623v01TsvjAw7HpbPxuELgNlifDa6a5HXROsMutbtm9m7PGavmR7E9XAZ9/o90//OgYiIET0u2phUgJCRBTDTkCICNJCiIgORuzyrOmuxj7r+1mGTpJWTHcdJmvQ6jxo9YX+qHOrhZBpx/1r2v/jezBodR60+kJf1Fns8UG1tn6WLkNEA6onJvX3xV7HlASEg3WI53B44+edw2EcqXl9vrRjpKmq83Nf+Gj3TD141sLZnLxkzpT8G/9o02HdM/Vgqv6NH+MRnvDjtdv4/d4dqGNKAsIcDufFetKTnqJB69b19FyRaXXGr0z4qMe+s8E31M5rq++7A3WkyxDRkOG0ECICqmnHJzz4l9Pgv4OIPpBBxYgYYU+WLkcEVF2GPWkhRETLcGYZIgJaS5cTECKCmXNzUwJCRANssjApIlqUhUkRUTFpIUREhwwqRgRQDSrmmYoR0ZYWQkQAmXaMiA7VNzelhRARxUx4YlKtkCZpqaQfStom6aKprlTEoLHFsA+qtdUh6c8kbZZ0h6SrJc0pX3i8QdJWSV8oX36MpEPK/rZy/Lhe30fX2kmaBVwKnAmcAJwr6YReC4yYqZp66rKkhcCfAifbfgEwi+pbzy8BPmZ7MfAg0PoS4fOAB20/B/hYydeTOuHqFGCb7btsPwF8HljWa4ERM1H1gBTV2mqaDRwqaTZwGLADOA24thxfDZxdXi8r+5Tjp0vqqf9SJyAsBO7u2B8qaSNIWiFpo6SNu3i8l7pEDLBJfS/D/Na1UrYR3yth+3+Bvwd+ShUIdgK3Ag/Z3l2ydV6H7Wu0HN8JHN3Lu6gzqDhWpHnSI69trwRWAgP3qPSIfWWYzLTjfbZPHu+gpKOoPvWPBx4CvkjVZR+rWKh5jdZRJyAMAcd27C8CtvdSWMRM1fBKxVcDP7Z9L4Ck64CXAnMlzS6tgM7rsHWNDpUuxtOAB3opuE6X4RZgcRnhPJhqcGNNL4VFzGTDHFRrq+GnwKmSDitjAacDPwBuBN5Q8iwHri+v15R9yvFv2p6aFoLt3ZIuANZRjXZebntzL4VFzFTV8xCaaSHY3iDpWuA2YDfwXaru+FeBz0v6cElbVX5lFXClpG1ULYM39lp2rYVJttcCa3stJOJA0OTNTbYvBi4elXwX1azf6LyPAec0UW5WKkY0oBpDyNLliChmwtLlBISIBhixezh3O0ZEkWcqRgTQ7CzDdEpAiGhIBhUjAsgzFSNilIwhRATQeoRaAkJEADjTjhFRtB6QMugSECIaki5DRAAZQ4iIURIQIgLIOoSI6GTYnZWKEQEZQ4iIURIQIgLIGEJEjOIEhIhoyUrFiACqB6SkyxARhdgznGnHiCgyhhARQNYhREQnV+MIgy4BIaIhmWWICKDqMmQMISKKrFSMiA7DwwkIEUE1oJguQ0S0pcsQEW2ZdoyItnQZIgKonocwEwJC17sxJF0u6R5Jd+yPCkUMKtfc6pA0V9K1ku6UtEXSSyTNk7Re0tby86iSV5I+KWmbpE2STur1PdS5PeuzwNJeC4g4IBg8rFpbTZ8Avm7714ElwBbgIuAG24uBG8o+wJnA4rKtAC7r9W10DQi2vwU80GsBEQcKW7W2biQdCfwmsKo6r5+w/RCwDFhdsq0Gzi6vlwFXuPJtYK6kBb28h8G/gTuiT9j1thp+FbgX+Iyk70r6tKTDgWNs76jK8g7gGSX/QuDujt8fKmmT1lhAkLRC0kZJG3fxeFOnjRgIrXsZarYQ5reulbKtGHW62cBJwGW2XwQ8wt7uwVjGanb0NAna2CyD7ZXASoAjNW8GzMhGTIKB+rMM99k+eYLjQ8CQ7Q1l/1qqgPAzSQts7yhdgns68h/b8fuLgO21694hXYaIhjTVZbD9f8Ddkp5Xkk4HfgCsAZaXtOXA9eX1GuCtZbbhVGBnq2sxWV1bCJKuBl5J1cwZAi62vaqXwiJmtGbbxe8ArpJ0MHAX8DaqD/BrJJ0H/BQ4p+RdC5wFbAMeLXl70jUg2D6315NHHDgmNaXYle3bgbG6FaePkdfA+U2Um5WKEU3I3Y4RMcIMGEpPQIhoTFoIEdGSFkJEtCUgRATQvrlp0CUgRDQlLYSIaMu0Y0S0KC2EiAAm9zikPpaAENEIpcsQER3SQoiItuHprsC+S0CIaMLkHpDStxIQIhqSWYaI2GsGBIQ8Qi0i2tJCiGhIugwRsVcGFSMCqMYPMu0YES3pMkTEXgkIEdGWgBARUHUX0mWIiL0yyxARbWkhRESLMu0YEQBkDCEiRkhAiIi2BISIaJkJXYbc/hwRbWkhRDRlBrQQEhAimuBMO0ZEp7QQIgJAHCCDipKOlXSjpC2SNkt65/6oWMTAcc2tJkmzJH1X0lfK/vGSNkjaKukLkg4u6YeU/W3l+HG9voU6swy7gQttPx84FThf0gm9FhgxI3nvHY/dtkl4J7ClY/8S4GO2FwMPAueV9POAB20/B/hYydeTrgHB9g7bt5XXD5cKLuy1wIgZq8EWgqRFwOuAT5d9AacB15Ysq4Gzy+tlZZ9y/PSSf9ImtQ6hNEVeBGzopbCImUzD9baaPg68h71PajwaeMj27rI/xN4P5oXA3QDl+M6Sf9JqBwRJRwBfAt5l++djHF8haaOkjbt4vJe6RAy2+i2E+a1rpWwrOk8j6fXAPbZv7Uwep8Ruxyal1iyDpKdQBYOrbF83Vh7bK4GVAEdq3gwYb42YhMkNGN5n++QJjr8M+G1JZwFzgCOpWgxzJc0urYBFwPaSfwg4FhiSNBt4GvDApN8D9WYZBKwCttj+aC+FRBwImhpUtP1e24tsHwe8Efim7TcDNwJvKNmWA9eX12vKPuX4N2339KFcp8vwMuAtwGmSbi/bWb0UFjGjNTztOIa/AN4taRvVGMGqkr4KOLqkvxu4qNcCunYZbN/M2H2UiOgwFQuTbN8E3FRe3wWcMkaex4BzmigvKxUjmjIDRs4SECIakMewR8RICQgR0ZIWQkTslYAQEW0JCBEB5HsZImKUBISIaMkzFSOiLV2GiKjs+30KfSEBIaIpCQgRATPnqcsJCBFNSUCIiBb19kySvpKAENGEfJVbRIww+A2EBISIpmRQMSL2SkCICCA3N0XEKAkIEQFZmBQRo2h48CNCAkJEE3JzU0R0ysKkiNgrLYSIaMmgYkRUDOTmpohoyRhCRABZhxARnex0GSJir7QQImKvBISIaEkLISIqBnIvQ0S0zIRpx4O6ZZA0R9J3JH1P0mZJH9ofFYsYOK2Zhm5bF5KOlXSjpC3lmntnSZ8nab2kreXnUSVdkj4paZukTZJO6vUtdA0IwOPAabaXACcCSyWd2muBETOVXG+rYTdwoe3nA6cC50s6AbgIuMH2YuCGsg9wJrC4bCuAy3p9D10Dgiu/KLtPKdvgd5YimuRJbN1OZe+wfVt5/TCwBVgILANWl2yrgbPL62XAFeVa/TYwV9KCXt5GnRYCkmZJuh24B1hve8MYeVZI2ihp4y4e76UuEQOrWqnoWhswv3WtlG3FuOeVjgNeBGwAjrG9A6qgATyjZFsI3N3xa0MlbdJqDSra3gOcKGku8GVJL7B9x6g8K4GVAEdqXloQceCpP6h4n+2Tu2WSdATwJeBdtn8uadysY6T1dA3WaiG0S7AfAm4ClvZSWMRMNokWQvdzSU+hCgZX2b6uJP+s1RUoP+8p6UPAsR2/vgjY3st7qDPL8PTSMkDSocCrgTt7KSxixrKrdQh1ti5UNQVWAVtsf7Tj0BpgeXm9HLi+I/2tZbbhVGBnq2sxWXW6DAuA1ZJmUQWQa2x/pZfCImayBlcqvgx4C/D9MnYH8D7gI8A1ks4DfgqcU46tBc4CtgGPAm/rteCuAcH2JqpBjYiYSEN3O9q+mbHHBQBOHyO/gfObKDsrFSOakG9/jogR8jyEiGgb/HiQgBDRlLpTiv0sASGiCQb2JCBEBCDqLzrqZwkIEU1JQIiItgSEiADKI9SmuxL7LgEhoiEZQ4iIvRIQIgIodzsOfp8hASGiKYMfDxIQIpqSMYSI2CsBISKAfHPTRB7mwfv+w9f+ZApOPR+4bwrOO5WmpM6zenrIdi1T+G+8bWpOO3V1fnb9rPk6+HHZfvpUnFfSxjpPq+0ng1bnQasv9FGdExAiAih3Ow7+NEMCQkQjDE5A2N9WTncFejBodR60+kK/1Dldhv2rfDvUQBm0Og9afaFP6pxZhogYIS2EiGhLQIgIoAoGe/ZMdy32WQJCRFPSQoiItgSEiKjU+2bnfpeAENEEg7MwKSLa0kKIiLaMIUQEkGnHiBjJechqRFTygJSIaJkhNzcdNN0ViJgxPFxvq0HSUkk/lLRN0kVTXPO2tBAiGmDADbUQJM0CLgVeAwwBt0haY/sHjRQwgbQQIppgN9lCOAXYZvsu208AnweWTWn9i7QQIhri5qYdFwJ3d+wPAS9u6uQTSUCIaMDDPLjuP3zt/JrZ50ja2LG/ctRTnzTG7+yXEcsEhIgG2F7a4OmGgGM79hcB2xs8/7gyhhDRf24BFks6XtLBwBuBNfuj4LQQIvqM7d2SLgDWAbOAy21v3h9lyzNgdVVENCNdhohoS0CIiLYEhIhoS0CIiLYEhIhoS0CIiLYEhIhoS0CIiLb/BzmcPYxEdNk3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate=0\n",
    "    total=0\n",
    "    y_pred=[]\n",
    "    curr=0\n",
    "    for i in range(200):\n",
    "        tstx=[]\n",
    "        tsty=[]\n",
    "        for j in range(bsize):\n",
    "            tstx.append(test_x[j+curr])\n",
    "            tsty.append(test_y[j+curr])\n",
    "        curr=curr+bsize\n",
    "        tstx=np.array(tstx).astype(np.float32)\n",
    "        tsty=np.array(tsty).astype(np.long)\n",
    "        \n",
    "        print(np.shape(tstx))\n",
    "\n",
    "        tstx=torch.from_numpy(tstx)\n",
    "        tsty=torch.from_numpy(tsty)\n",
    "        \n",
    "        output=model(tstx)\n",
    "        _, predicted=torch.max(output.data,1)\n",
    "        y_pred.extend(predicted.numpy().tolist())\n",
    "        total=total+tsty.size(0)\n",
    "        accurate=accurate+(predicted==tsty).sum().item()\n",
    "    print(np.shape(y_pred))\n",
    "#     y_pred=clf.predict(test_x)\n",
    "    cm = confusion_matrix(test_y, y_pred)\n",
    "    print(np.sum(np.diagonal(cm))/np.sum(cm))\n",
    "    plt.clf()\n",
    "    plt.matshow(cm)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(\"ConfusionLR\")\n",
    "    print(\"Accuracy :\",accurate/total)\n",
    "\n",
    "\n",
    "train_x=torch.from_numpy(train_x)\n",
    "train_y=torch.from_numpy(train_y)\n",
    "test_x=torch.from_numpy(test_x)\n",
    "test_y=torch.from_numpy(test_y)\n",
    "print(train_x.size(),train_y.size(),test_x.size(),test_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/500], Loss: 2.2286\n",
      "Epoch [1/5], Step [200/500], Loss: 2.1884\n",
      "Epoch [1/5], Step [300/500], Loss: 2.1278\n",
      "Epoch [1/5], Step [400/500], Loss: 2.0862\n",
      "Epoch [1/5], Step [500/500], Loss: 2.2566\n",
      "Epoch [2/5], Step [100/500], Loss: 2.2720\n",
      "Epoch [2/5], Step [200/500], Loss: 2.2945\n",
      "Epoch [2/5], Step [300/500], Loss: 2.2667\n",
      "Epoch [2/5], Step [400/500], Loss: 2.2271\n",
      "Epoch [2/5], Step [500/500], Loss: 2.2667\n",
      "Epoch [3/5], Step [100/500], Loss: 2.1516\n",
      "Epoch [3/5], Step [200/500], Loss: 2.1612\n",
      "Epoch [3/5], Step [300/500], Loss: 2.1846\n",
      "Epoch [3/5], Step [400/500], Loss: 2.1980\n",
      "Epoch [3/5], Step [500/500], Loss: 2.2660\n",
      "Epoch [4/5], Step [100/500], Loss: 2.2612\n",
      "Epoch [4/5], Step [200/500], Loss: 2.2220\n",
      "Epoch [4/5], Step [300/500], Loss: 2.2469\n",
      "Epoch [4/5], Step [400/500], Loss: 2.2612\n",
      "Epoch [4/5], Step [500/500], Loss: 2.2945\n",
      "Epoch [5/5], Step [100/500], Loss: 2.2339\n",
      "Epoch [5/5], Step [200/500], Loss: 2.3260\n",
      "Epoch [5/5], Step [300/500], Loss: 2.2751\n",
      "Epoch [5/5], Step [400/500], Loss: 2.2339\n",
      "Epoch [5/5], Step [500/500], Loss: 2.1754\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#[batchsize,learning_rate,epochs,classes]\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(trainset)\n",
    "for epoch in range(param[2]):\n",
    "    for i, data in enumerate(trainset):\n",
    "        images, labels = data\n",
    "        imgs1=images[labels==1]\n",
    "        imgs3=images[labels==3]\n",
    "        imgs5=images[labels==5]\n",
    "        imgs9=images[labels==9]\n",
    "        imgs1=torch.cat([imgs1, imgs3], 0)\n",
    "        imgs1=torch.cat([imgs1, imgs5], 0)\n",
    "        imgs1=torch.cat([imgs1, imgs9], 0)\n",
    "#         tf.concat([imgs1, imgs5], 0)\n",
    "#         tf.concat([imgs1, imgs9], 0)\n",
    "        \n",
    "#         lbl1=labels[labels==1]\n",
    "#         lbl3=labels[labels==3]\n",
    "#         lbl5=labels[labels==5]\n",
    "#         lbl9=labels[labels==9]\n",
    "#         lbl1=torch.cat([lbl1, lbl3], 0)\n",
    "#         lbl1=torch.cat([lbl1, lbl5], 0)\n",
    "#         lbl1=torch.cat([lbl1, lbl9], 0)\n",
    "\n",
    "        lbl1=np.zeros(len(labels[labels==1]))\n",
    "        lbl3=np.zeros(len(labels[labels==3]))+1\n",
    "        lbl5=np.zeros(len(labels[labels==5]))+2\n",
    "        lbl9=np.zeros(len(labels[labels==9]))+3\n",
    "        lbl1=np.concatenate((lbl1, lbl3), axis=0)\n",
    "        lbl1=np.concatenate((lbl1, lbl5), axis=0)\n",
    "        lbl1=np.concatenate((lbl1, lbl9), axis=0)\n",
    "        \n",
    "        lbl1 = torch.tensor(lbl1.astype(np.long))\n",
    "        \n",
    "#         tf.concat([lbl1, lbl3], 0)\n",
    "#         tf.concat([lbl1, lbl5], 0)\n",
    "#         tf.concat([lbl1, lbl9], 0)\n",
    "    \n",
    "        outputs = model(imgs1)\n",
    "#         print(np.shape(outputs),np.shape(lbl1))\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, lbl1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, param[2], i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.25\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accurate=0\n",
    "    total=0\n",
    "    for images, labels in testset:\n",
    "        imgs1=images[labels==1]\n",
    "        imgs3=images[labels==3]\n",
    "        imgs5=images[labels==5]\n",
    "        imgs9=images[labels==9]\n",
    "        imgs1=torch.cat([imgs1, imgs3], 0)\n",
    "        imgs1=torch.cat([imgs1, imgs5], 0)\n",
    "        imgs1=torch.cat([imgs1, imgs9], 0)\n",
    "#         tf.concat([imgs1, imgs3], 0)\n",
    "#         tf.concat([imgs1, imgs5], 0)\n",
    "#         tf.concat([imgs1, imgs9], 0)\n",
    "        \n",
    "#         lbl1=labels[labels==1]\n",
    "#         lbl3=labels[labels==3]\n",
    "#         lbl5=labels[labels==5]\n",
    "#         lbl9=labels[labels==9]\n",
    "#         lbl1=torch.cat([lbl1, lbl3], 0)\n",
    "#         lbl1=torch.cat([lbl1, lbl5], 0)\n",
    "#         lbl1=torch.cat([lbl1, lbl9], 0)\n",
    "        \n",
    "        \n",
    "        lbl1=np.zeros(len(labels[labels==1]))\n",
    "        lbl3=np.zeros(len(labels[labels==3]))+1\n",
    "        lbl5=np.zeros(len(labels[labels==5]))+2\n",
    "        lbl9=np.zeros(len(labels[labels==9]))+3\n",
    "        lbl1=np.concatenate((lbl1, lbl3), axis=0)\n",
    "        lbl1=np.concatenate((lbl1, lbl5), axis=0)\n",
    "        lbl1=np.concatenate((lbl1, lbl9), axis=0)\n",
    "        \n",
    "        lbl1 = torch.tensor(lbl1.astype(np.long))\n",
    "        \n",
    "        \n",
    "#         tf.concat([lbl1, lbl3], 0)\n",
    "#         tf.concat([lbl1, lbl5], 0)\n",
    "#         tf.concat([lbl1, lbl9], 0)\n",
    "        output=model(imgs1)\n",
    "        _, predicted=torch.max(output.data,1)\n",
    "        p=predicted.numpy()\n",
    "        total=total+lbl1.size(0)\n",
    "        accurate=accurate+(predicted==lbl1).sum().item()\n",
    "#         print(accurate)\n",
    "    print(\"Accuracy :\",accurate/total)\n",
    "\n",
    "torch.save(model.state_dict(),\"Model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
